{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy\n",
    "from torch import autograd, nn, optim\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import re\n",
    "import random\n",
    "import time\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SOS_TOKEN = 0\n",
    "EOS_TOKEN = 1\n",
    "MAX_LENGTH = 20\n",
    "\n",
    "class Lang:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.index2word = {}\n",
    "        self.word2count = {}\n",
    "        self.n_words = 2\n",
    "    \n",
    "    def index_sentence(self, sentence):\n",
    "        for w in sentence.split(' '):\n",
    "            self.index_word(w)\n",
    "            \n",
    "    def index_word(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.word2count[word] = 1\n",
    "            self.n_words = self.n_words + 1\n",
    "        else:\n",
    "            self.word2count[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize_string(s):\n",
    "    s = s.lower().strip()\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"[^a-zA-Zא-ת.!?]+\", r\" \", s)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_langs(lang1, lang2, reverse=False):\n",
    "    print(\"Reading lines...\")\n",
    "\n",
    "    # Read the file and split into lines\n",
    "    lines = open('data/%s-%s.txt' % (lang1, lang2)).read().strip().split('\\n')\n",
    "    \n",
    "    # Split every line into pairs and normalize\n",
    "    pairs = [[normalize_string(s) for s in l.split('\\t')] for l in lines]\n",
    "    \n",
    "    # Reverse pairs, make Lang instances\n",
    "    if reverse:\n",
    "        pairs = [list(reversed(p)) for p in pairs]\n",
    "        input_lang = Lang(lang2)\n",
    "        output_lang = Lang(lang1)\n",
    "    else:\n",
    "        input_lang = Lang(lang1)\n",
    "        output_lang = Lang(lang2)\n",
    "        \n",
    "    return input_lang, output_lang, pairs\n",
    "\n",
    "\n",
    "def print_pair(p):\n",
    "    print p[0]\n",
    "    print p[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MAX_LENGTH = 10\n",
    "\n",
    "good_prefixes = (\n",
    "    \"i am \", \"i m \",\n",
    "    \"he is\", \"he s \",\n",
    "    \"she is\", \"she s\",\n",
    "    \"you are\", \"you re \"\n",
    ")\n",
    "\n",
    "def filter_pair(p):\n",
    "    return len(p[0].split(' ')) < MAX_LENGTH and len(p[1].split(' ')) < MAX_LENGTH and \\\n",
    "        p[1].startswith(good_prefixes)\n",
    "\n",
    "def filter_pairs(pairs):\n",
    "    return [pair for pair in pairs if filter_pair(pair)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n",
      "Read 125860 sentence pairs\n",
      "Trimmed to 7646 sentence pairs\n",
      "Indexing words...\n",
      "אין לו את היכולות .\n",
      "he is incompetent .\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "def prepare_data(lang1_name, lang2_name, reverse=False):\n",
    "    input_lang, output_lang, pairs = read_langs(lang1_name, lang2_name, reverse)\n",
    "    print(\"Read %s sentence pairs\" % len(pairs))\n",
    "    \n",
    "    pairs = filter_pairs(pairs)\n",
    "    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
    "\n",
    "    \n",
    "    print(\"Indexing words...\")\n",
    "    for pair in pairs:\n",
    "        input_lang.index_sentence(pair[0])\n",
    "        output_lang.index_sentence(pair[1])\n",
    "\n",
    "    return input_lang, output_lang, pairs\n",
    "\n",
    "input_lang, output_lang, pairs = prepare_data('eng', 'heb', True)\n",
    "\n",
    "# Print an example pair\n",
    "print(print_pair(random.choice(pairs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def indexes_from_sentence(lang, sentence):\n",
    "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
    "\n",
    "\n",
    "def variable_from_sentence(lang, sentence):\n",
    "    indexes = indexes_from_sentence(lang, sentence)\n",
    "    indexes.append(EOS_TOKEN)\n",
    "    return Variable(torch.LongTensor(indexes).view(-1, 1))\n",
    "    \n",
    "\n",
    "def variables_from_pair(pair):\n",
    "    input_variable = variable_from_sentence(input_lang, pair[0])\n",
    "    target_variable = variable_from_sentence(output_lang, pair[1])\n",
    "    return (input_variable, target_variable)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, n_layers=1):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        \n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, n_layers)\n",
    "        \n",
    "    def forward(self, word_inputs, hidden):\n",
    "        seq_len = len(word_inputs)\n",
    "        embedded = self.embedding(word_inputs).view(seq_len, 1, -1)\n",
    "        output, hidden = self.gru(embedded, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def init_hidden(self):\n",
    "        hidden = Variable(torch.zeros(self.n_layers, 1, self.hidden_size))\n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attn(nn.Module):\n",
    "    def __init__(self, method, hidden_size, max_length=MAX_LENGTH):\n",
    "        super(Attn, self).__init__()\n",
    "        \n",
    "        self.method = method\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        if self.method == 'general':\n",
    "            self.attn = nn.Linear(self.hidden_size, hidden_size)\n",
    "\n",
    "        elif self.method == 'concat':\n",
    "            self.attn = nn.Linear(self.hidden_size * 2, hidden_size)\n",
    "            self.other = nn.Parameter(torch.FloatTensor(1, hidden_size))\n",
    "\n",
    "    def forward(self, hidden, encoder_outputs):\n",
    "        seq_len = len(encoder_outputs)\n",
    "\n",
    "        attn_energies = Variable(torch.zeros(seq_len)) # B x 1 x S\n",
    "\n",
    "        for i in range(seq_len):\n",
    "            attn_energies[i] = self.score(hidden, encoder_outputs[i])\n",
    "\n",
    "        # Normalize energies to weights in range 0 to 1, resize to 1 x 1 x seq_len\n",
    "        return F.softmax(attn_energies).unsqueeze(0).unsqueeze(0)\n",
    "    \n",
    "    def score(self, hidden, encoder_output):\n",
    "        \n",
    "        if self.method == 'dot':\n",
    "            energy = hidden.dot(encoder_output)\n",
    "            return energy\n",
    "        \n",
    "        elif self.method == 'general':\n",
    "            energy = self.attn(encoder_output)\n",
    "            energy = hidden.view(-1).dot(energy.view(-1))\n",
    "            return energy\n",
    "        \n",
    "        elif self.method == 'concat':\n",
    "            energy = self.attn(torch.cat((hidden, encoder_output), 1))\n",
    "            energy = self.other.dot(energy)\n",
    "            return energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class AttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, attn_model, hidden_size, output_size, n_layers=1, dropout_p=0.1):\n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        \n",
    "        # Keep parameters for reference\n",
    "        self.attn_model = attn_model\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout_p = dropout_p\n",
    "        \n",
    "        # Define layers\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size * 2, hidden_size, n_layers, dropout=dropout_p)\n",
    "        self.out = nn.Linear(hidden_size * 2, output_size)\n",
    "        \n",
    "        # Choose attention model\n",
    "        if attn_model != 'none':\n",
    "            self.attn = Attn(attn_model, hidden_size)\n",
    "    \n",
    "    def forward(self, word_input, last_context, last_hidden, encoder_outputs):\n",
    "        # Note: we run this one step at a time\n",
    "        \n",
    "        # Get the embedding of the current input word (last output word)\n",
    "        word_embedded = self.embedding(word_input).view(1, 1, -1) # S=1 x B x N\n",
    "        \n",
    "        # Combine embedded input word and last context, run through RNN\n",
    "        rnn_input = torch.cat((word_embedded, last_context.unsqueeze(0)), 2)\n",
    "        rnn_output, hidden = self.gru(rnn_input, last_hidden)\n",
    "\n",
    "        # Calculate attention from current RNN state and all encoder outputs; apply to encoder outputs\n",
    "        #print rnn_output.squeeze(0).squeeze(0).size()\n",
    "        attn_weights = self.attn(rnn_output.squeeze(0), encoder_outputs)\n",
    "        context = attn_weights.bmm(encoder_outputs.transpose(0, 1)) # B x 1 x N\n",
    "        \n",
    "        # Final output layer (next word prediction) using the RNN hidden state and context vector\n",
    "        rnn_output = rnn_output.squeeze(0) # S=1 x B x N -> B x N\n",
    "        context = context.squeeze(1)       # B x S=1 x N -> B x N\n",
    "        output = F.log_softmax(self.out(torch.cat((rnn_output, context), 1)))\n",
    "        \n",
    "        # Return final output, hidden state, and attention weights (for visualization)\n",
    "        return output, context, hidden, attn_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(torch.Size([1, 10]), torch.Size([2, 1, 10]), torch.Size([1, 1, 3]))\n",
      "(torch.Size([1, 10]), torch.Size([2, 1, 10]), torch.Size([1, 1, 3]))\n",
      "(torch.Size([1, 10]), torch.Size([2, 1, 10]), torch.Size([1, 1, 3]))\n"
     ]
    }
   ],
   "source": [
    "# Testing\n",
    "\n",
    "encoder_test = EncoderRNN(10, 10, 2)\n",
    "decoder_test = AttnDecoderRNN('general', 10, 10, 2)\n",
    "\n",
    "encoder_hidden = encoder_test.init_hidden()\n",
    "\n",
    "word_input = Variable(torch.LongTensor([1, 2, 3]))\n",
    "encoder_outputs, encoder_hidden = encoder_test(word_input, encoder_hidden)\n",
    "\n",
    "word_inputs = Variable(torch.LongTensor([1, 2, 3]))\n",
    "decoder_attns = torch.zeros(1, 3, 3)\n",
    "decoder_hidden = encoder_hidden\n",
    "decoder_context = Variable(torch.zeros(1, decoder_test.hidden_size))\n",
    "\n",
    "for i in range(3):\n",
    "    decoder_output, decoder_context, decoder_hidden, decoder_attn = decoder_test(word_inputs[i], decoder_context, decoder_hidden, encoder_outputs)\n",
    "    print(decoder_output.size(), decoder_hidden.size(), decoder_attn.size())\n",
    "    decoder_attns[0, i] = decoder_attn.squeeze(0).cpu().data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "teacher_forcing_ratio = 0.5\n",
    "clip = 5.0\n",
    "\n",
    "def train(input_variable, target_variable, encoder, decoder, \n",
    "          encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
    "\n",
    "    # Zero gradients of both optimizers\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "    loss = 0 # Added onto for each word\n",
    "\n",
    "    # Get size of input and target sentences\n",
    "    input_length = input_variable.size()[0]\n",
    "    target_length = target_variable.size()[0]\n",
    "\n",
    "    # Run words through encoder\n",
    "    encoder_hidden = encoder.init_hidden()\n",
    "    encoder_outputs, encoder_hidden = encoder(input_variable, encoder_hidden)\n",
    "    \n",
    "    # Prepare input and output variables\n",
    "    decoder_input = Variable(torch.LongTensor([[SOS_TOKEN]]))\n",
    "    decoder_context = Variable(torch.zeros(1, decoder.hidden_size))\n",
    "    decoder_hidden = encoder_hidden # Use last hidden state from encoder to start decoder\n",
    "\n",
    "    # Choose whether to use teacher forcing\n",
    "    use_teacher_forcing = random.random() < teacher_forcing_ratio\n",
    "    if use_teacher_forcing:\n",
    "        \n",
    "        # Teacher forcing: Use the ground-truth target as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_context, decoder_hidden, decoder_attention = decoder(decoder_input, decoder_context, decoder_hidden, encoder_outputs)\n",
    "            loss += criterion(decoder_output[0].view(1, -1), target_variable[di])\n",
    "            decoder_input = target_variable[di] # Next target is next input\n",
    "\n",
    "    else:\n",
    "        # Without teacher forcing: use network's own prediction as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_context, decoder_hidden, decoder_attention = decoder(decoder_input, decoder_context, decoder_hidden, encoder_outputs)           \n",
    "            loss += criterion(decoder_output[0].view(1, -1), target_variable[di])\n",
    "            \n",
    "            # Get most likely word index (highest value) from output\n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "            ni = topi[0][0]\n",
    "            \n",
    "            decoder_input = Variable(torch.LongTensor([[ni]])) # Chosen word is next input\n",
    "\n",
    "            # Stop at end of sentence (not necessary when using known targets)\n",
    "            if ni == EOS_TOKEN: break\n",
    "\n",
    "    # Backpropagation\n",
    "    loss.backward()\n",
    "    torch.nn.utils.clip_grad_norm(encoder.parameters(), clip)\n",
    "    torch.nn.utils.clip_grad_norm(decoder.parameters(), clip)\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "    \n",
    "    return loss.data[0] / target_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def as_minutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "def time_since(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (as_minutes(s), as_minutes(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_model = 'general'\n",
    "hidden_size = 500\n",
    "n_layers = 2\n",
    "dropout_p = 0.05\n",
    "\n",
    "# Initialize models\n",
    "encoder = EncoderRNN(input_lang.n_words, hidden_size, n_layers)\n",
    "decoder = AttnDecoderRNN(attn_model, hidden_size, output_lang.n_words, n_layers, dropout_p=dropout_p)\n",
    "\n",
    "# Initialize optimizers and criterion\n",
    "learning_rate = 0.0001\n",
    "encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
    "decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate)\n",
    "criterion = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 50000\n",
    "plot_every = 200\n",
    "print_every = 1000\n",
    "\n",
    "# Keep track of time elapsed and running averages\n",
    "start = time.time()\n",
    "plot_losses = []\n",
    "print_loss_total = 0 # Reset every print_every\n",
    "plot_loss_total = 0 # Reset every plot_every"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8m 37s (- 422m 46s) (1000 0%) 3.2776\n",
      "18m 22s (- 441m 6s) (2000 0%) 2.8848\n",
      "73m 34s (- 1152m 42s) (3000 0%) 2.7953\n",
      "84m 20s (- 970m 0s) (4000 0%) 2.6822\n",
      "108m 40s (- 978m 2s) (5000 0%) 2.5927\n",
      "122m 46s (- 900m 19s) (6000 0%) 2.5043\n",
      "137m 40s (- 845m 40s) (7000 0%) 2.4231\n",
      "152m 33s (- 800m 55s) (8000 0%) 2.3141\n",
      "173m 22s (- 789m 47s) (9000 0%) 2.2769\n",
      "188m 24s (- 753m 36s) (10000 0%) 2.1738\n",
      "203m 56s (- 723m 3s) (11000 0%) 2.1258\n",
      "217m 50s (- 689m 49s) (12000 0%) 1.9961\n",
      "309m 26s (- 880m 44s) (13000 0%) 2.0158\n",
      "322m 49s (- 830m 7s) (14000 0%) 1.9194\n",
      "579m 32s (- 1352m 15s) (15000 0%) 1.8421\n",
      "590m 48s (- 1255m 28s) (16000 0%) 1.7371\n",
      "603m 4s (- 1170m 41s) (17000 0%) 1.7410\n",
      "614m 21s (- 1092m 12s) (18000 0%) 1.6461\n",
      "626m 6s (- 1021m 32s) (19000 0%) 1.5953\n",
      "637m 31s (- 956m 17s) (20000 0%) 1.5110\n",
      "649m 39s (- 897m 9s) (21000 0%) 1.5109\n",
      "661m 23s (- 841m 46s) (22000 0%) 1.4601\n",
      "673m 18s (- 790m 24s) (23000 0%) 1.3562\n",
      "685m 4s (- 742m 10s) (24000 0%) 1.3205\n",
      "696m 57s (- 696m 57s) (25000 0%) 1.2550\n",
      "709m 10s (- 654m 37s) (26000 0%) 1.2930\n",
      "721m 29s (- 614m 36s) (27000 0%) 1.2453\n",
      "733m 23s (- 576m 14s) (28000 0%) 1.1353\n",
      "745m 24s (- 539m 46s) (29000 0%) 1.1188\n",
      "757m 24s (- 504m 56s) (30000 0%) 1.1246\n",
      "769m 2s (- 471m 21s) (31000 0%) 1.0884\n",
      "780m 31s (- 439m 2s) (32000 0%) 1.0531\n",
      "792m 4s (- 408m 2s) (33000 0%) 1.0044\n",
      "803m 37s (- 378m 10s) (34000 0%) 0.9142\n",
      "815m 13s (- 349m 23s) (35000 0%) 0.9228\n",
      "826m 45s (- 321m 30s) (36000 0%) 0.8300\n",
      "838m 20s (- 294m 33s) (37000 0%) 0.8456\n",
      "849m 53s (- 268m 23s) (38000 0%) 0.7903\n",
      "861m 24s (- 242m 57s) (39000 0%) 0.7610\n",
      "872m 56s (- 218m 14s) (40000 0%) 0.7898\n",
      "884m 31s (- 194m 9s) (41000 0%) 0.7222\n",
      "1283m 54s (- 244m 33s) (42000 0%) 0.7020\n",
      "1297m 36s (- 211m 14s) (43000 0%) 0.6442\n",
      "1312m 4s (- 178m 55s) (44000 0%) 0.6500\n",
      "1324m 39s (- 147m 11s) (45000 0%) 0.6288\n",
      "1338m 17s (- 116m 22s) (46000 0%) 0.6366\n",
      "1352m 28s (- 86m 19s) (47000 0%) 0.5904\n",
      "1365m 29s (- 56m 53s) (48000 0%) 0.5983\n",
      "1380m 1s (- 28m 9s) (49000 0%) 0.6101\n",
      "1393m 28s (- 0m 0s) (50000 100%) 0.5487\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# Begin!\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    \n",
    "    # Get training data for this cycle\n",
    "    training_pair = variables_from_pair(random.choice(pairs))\n",
    "    input_variable = training_pair[0]\n",
    "    target_variable = training_pair[1]\n",
    "\n",
    "    # Run the train function\n",
    "    loss = train(input_variable, target_variable, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "\n",
    "    # Keep track of loss\n",
    "    print_loss_total += loss\n",
    "    plot_loss_total += loss\n",
    "\n",
    "    if epoch == 0: continue\n",
    "\n",
    "    if epoch % print_every == 0:\n",
    "        print_loss_avg = print_loss_total / print_every\n",
    "        print_loss_total = 0\n",
    "\n",
    "        percent = float(float(epoch) / float(n_epochs))\n",
    "        print_summary = '%s (%d %d%%) %.4f' % (time_since(start, percent), epoch, epoch / n_epochs * 100, print_loss_avg)\n",
    "        print(print_summary)\n",
    "\n",
    "    if epoch % plot_every == 0:\n",
    "        plot_loss_avg = plot_loss_total / plot_every\n",
    "        plot_losses.append(plot_loss_avg)\n",
    "        plot_loss_total = 0\n",
    "        \n",
    "print \"Done!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1127317d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x115aa0b10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "def show_plot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    loc = ticker.MultipleLocator(base=0.2) # put ticks at regular intervals\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)\n",
    "\n",
    "show_plot(plot_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate(sentence, max_length=MAX_LENGTH):\n",
    "    input_variable = variable_from_sentence(input_lang, sentence)\n",
    "    input_length = input_variable.size()[0]\n",
    "    \n",
    "    # Run through encoder\n",
    "    encoder_hidden = encoder.init_hidden()\n",
    "    encoder_outputs, encoder_hidden = encoder(input_variable, encoder_hidden)\n",
    "\n",
    "    # Create starting vectors for decoder\n",
    "    decoder_input = Variable(torch.LongTensor([[SOS_TOKEN]])) # SOS\n",
    "    decoder_context = Variable(torch.zeros(1, decoder.hidden_size))\n",
    "\n",
    "    decoder_hidden = encoder_hidden\n",
    "    \n",
    "    decoded_words = []\n",
    "    decoder_attentions = torch.zeros(max_length, max_length)\n",
    "    \n",
    "    # Run through decoder\n",
    "    for di in range(max_length):\n",
    "        decoder_output, decoder_context, decoder_hidden, decoder_attention = decoder(decoder_input, decoder_context, decoder_hidden, encoder_outputs)\n",
    "        decoder_attentions[di,:decoder_attention.size(2)] += decoder_attention.squeeze(0).squeeze(0).cpu().data\n",
    "\n",
    "        # Choose top word from output\n",
    "        topv, topi = decoder_output.data.topk(1)\n",
    "        ni = topi[0][0]\n",
    "        if ni == EOS_TOKEN:\n",
    "            decoded_words.append('<EOS>')\n",
    "            break\n",
    "        else:\n",
    "            decoded_words.append(output_lang.index2word[ni])\n",
    "            \n",
    "        # Next input is chosen word\n",
    "        decoder_input = Variable(torch.LongTensor([[ni]]))\n",
    "    \n",
    "    return decoded_words, decoder_attentions[:di+1, :len(encoder_outputs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate_randomly():\n",
    "    pair = random.choice(pairs)\n",
    "    \n",
    "    output_words, decoder_attn = evaluate(pair[0])\n",
    "    output_sentence = ' '.join(output_words)\n",
    "    \n",
    "    print pair[0]\n",
    "    print pair[1]\n",
    "    print output_sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "אני לא מתכונן להכחיש את זה .\n",
      "i m not going to deny that .\n",
      "i m not going to deny that . <EOS>\n",
      "\n",
      "\n",
      "אני מרגיש בנוח עם זה .\n",
      "i m comfortable with it .\n",
      "i m horrible with this . <EOS>\n",
      "\n",
      "\n",
      "סלח לי .\n",
      "i m sorry .\n",
      "i m sorry . <EOS>\n",
      "\n",
      "\n",
      "אני מתכונן לגרוע מכל .\n",
      "i m getting ready for the worst .\n",
      "i m sorry for the bus in . <EOS>\n",
      "\n",
      "\n",
      "הוא לומד ממש עכשיו .\n",
      "he s now studying .\n",
      "he s now studying . <EOS>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    evaluate_randomly()\n",
    "    print '\\n'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
